---
layout:     post
title:      数据库比赛中的排序问题与CPU缓存行
subtitle:   CPU缓存行，Java对齐填充
date:       2019-03-12
author:     rosewind
header-img: img/animation/25.jpg
catalog: true
tags:
    - 算法
    - Java

---

# 前言

这段时间看《深入理解Java虚拟机》，看到了对象的内存布局，其中讲到了对齐填充(Padding)。让我回忆起了之前数据库比赛的一个大佬，提到的对key、offet的排序问题。

# key、value的排序问题

在这个比赛中，key为long类型，offset为int类型，要先进行排序，为后面顺序读做准备。

一个直接的想法就是2个属性放到1个类里面，进行排序。

```java
// wrong
public class KeyOffset {
    long key;
    int offset;
}
```

[PolarDB数据库性能大赛Java选手分享](https://github.com/lexburner/kiritoDB)提到这样会使得后面排序的效率变低，这是因为CPU缓存行的存在。

# 直观的例子

```java
public class Main {
    static long[][] arr;

    public static void main(String[] args) {
        arr = new long[1024 * 1024][8];
        // 横向遍历
        long marked = System.currentTimeMillis();
        for (int i = 0; i < 1024 * 1024; i += 1) {
            for (int j = 0; j < 8; j++) {
                sum += arr[i][j];
            }
        }
        System.out.println("Loop times:" + (System.currentTimeMillis() - marked) + "ms");

        marked = System.currentTimeMillis();
        // 纵向遍历
        for (int i = 0; i < 8; i += 1) {
            for (int j = 0; j < 1024 * 1024; j++) {
                sum += arr[j][i];
            }
        }
        System.out.println("Loop times:" + (System.currentTimeMillis() - marked) + "ms");
    }
}
```

> 事实上，在我的机器上（64 位 mac）多次运行后可以发现：横向遍历的耗时大约为 25 ms，纵向遍历的耗时大约为 60 ms，前者比后者快了 1 倍有余。

# CPU高速缓存

![](http://kirito.iocoder.cn/10538467-7923f58c663c7db1.png)

### 为什么需要有 CPU 高速缓存？

随着工艺的提升，最近几十年 CPU 的频率不断提升，而受制于制造工艺和成本限制，目前计算机的内存在访问速度上没有质的突破。因此，CPU 的处理速度和内存的访问速度差距越来越大，甚至可以达到上万倍。这种情况下传统的 CPU 直连内存的方式显然就会因为内存访问的等待，导致计算资源大量闲置，降低 CPU 整体吞吐量。同时又由于内存数据访问的热点集中性，在 CPU 和内存之间用较为快速而成本较高（相对于内存）的介质做一层缓存，就显得性价比极高了。

### 为什么需要有 CPU 多级缓存？

结合 图片 – CPU 缓存架构，再来看一组 CPU 各级缓存存取速度的对比

1. 各种寄存器，用来存储本地变量和函数参数，访问一次需要1cycle，耗时小于1ns；
2. L1 Cache，一级缓存，本地 core 的缓存，分成 32K 的数据缓存 L1d 和 32k 指令缓存 L1i，访问 L1 需要3cycles，耗时大约 1ns；
3. L2 Cache，二级缓存，本地 core 的缓存，被设计为 L1 缓存与共享的 L3 缓存之间的缓冲，大小为 256K，访问 L2 需要 12cycles，耗时大约 3ns；
4. L3 Cache，三级缓存，在同插槽的所有 core 共享 L3 缓存，分为多个 2M 的段，访问 L3 需要 38cycles，耗时大约 12ns；

大致可以得出结论，缓存层级越接近于 CPU core，容量越小，速度越快，同时，没有披露的一点是其造价也更贵。所以为了支撑更多的热点数据，同时追求最高的性价比，多级缓存架构应运而生。

### 什么是缓存行(Cache Line)？

上面我们介绍了 CPU 多级缓存的概念，而之后的章节我们将尝试忽略“多级”这个特性，将之合并为 CPU 缓存，这对于我们理解 CPU 缓存的工作原理并无大碍。

缓存行 (Cache Line) 便是 CPU Cache 中的最小单位，CPU Cache 由若干缓存行组成，一个缓存行的大小通常是 64 字节（这取决于 CPU），并且它有效地引用主内存中的一块地址。一个 Java 的 long 类型是 8 字节，因此在一个缓存行中可以存 8 个 long 类型的变量。

![](http://kirito.iocoder.cn/%E5%A4%9A%E7%BA%A7%E7%BC%93%E5%AD%98.png)

试想一下你正在遍历一个长度为 16 的 long 数组 data[16]，原始数据自然存在于主内存中，访问过程描述如下

1. 访问 data[0]，CPU core 尝试访问 CPU Cache，未命中。
2. 尝试访问主内存，操作系统一次访问的单位是一个 Cache Line 的大小 — 64 字节，这意味着：既从主内存中获取到了 data[0] 的值，同时将 data[0] ~ data[7] 加入到了 CPU Cache 之中，for free~
3. 访问 data[1]~data[7]，CPU core 尝试访问 CPU Cache，命中直接返回。
4. 访问 data[8]，CPU core 尝试访问 CPU Cache，未命中。
5. 尝试访问主内存。重复步骤 2

CPU 缓存在顺序访问连续内存数据时挥发出了最大的优势。试想一下上一篇文章中提到的 PageCache，其实发生在磁盘 IO 和内存之间的缓存，是不是有异曲同工之妙？只不过今天的主角— CPU Cache，相比 PageCache 更加的微观。

再回到文章的开头，为何横向遍历 `arr = new long[1024 * 1024][8]` 要比纵向遍历更快？此处得到了解答，正是更加友好地利用 CPU Cache 带来的优势，甚至有一个专门的词来修饰这种行为 — Mechanical Sympathy。

### 伪共享

通常提到缓存行，大多数文章都会提到伪共享问题（正如提到 CAS 便会提到 ABA 问题一般）。

伪共享指的是多个线程同时读写同一个缓存行的不同变量时导致的 CPU 缓存失效。尽管这些变量之间没有任何关系，但由于在主内存中邻近，存在于同一个缓存行之中，它们的相互覆盖会导致频繁的缓存未命中，引发性能下降。伪共享问题难以被定位，如果系统设计者不理解 CPU 缓存架构，甚至永远无法发现 — 原来我的程序还可以更快。

[![伪共享](http://kirito.iocoder.cn/%E4%BC%AA%E5%85%B1%E4%BA%AB.png)](http://kirito.iocoder.cn/%E4%BC%AA%E5%85%B1%E4%BA%AB.png)伪共享伪共享

正如图中所述，如果多个线程的变量共享了同一个 CacheLine，任意一方的修改操作都会使得整个 CacheLine 失效（因为 CacheLine 是 CPU 缓存的最小单位），也就意味着，频繁的多线程操作，CPU 缓存将会彻底失效，降级为 CPU core 和主内存的直接交互。

伪共享问题的解决方法便是字节填充。

[![伪共享-字节填充](http://kirito.iocoder.cn/%E4%BC%AA%E5%85%B1%E4%BA%AB-%E5%AD%97%E8%8A%82%E5%A1%AB%E5%85%85.png)](http://kirito.iocoder.cn/%E4%BC%AA%E5%85%B1%E4%BA%AB-%E5%AD%97%E8%8A%82%E5%A1%AB%E5%85%85.png)伪共享-字节填充伪共享-字节填充

我们只需要保证不同线程的变量存在于不同的 CacheLine 即可，使用多余的字节来填充可以做点这一点，这样就不会出现伪共享问题。在代码层面如何实现图中的字节填充呢？

### Java6 中实现字节填充

```java
public class PaddingObject{
    public volatile long value = 0L;    // 实际数据
    public long p1, p2, p3, p4, p5, p6; // 填充
}
```

PaddingObject 类中需要保存一个 long 类型的 value 值，如果多线程操作同一个 CacheLine 中的 PaddingObject 对象，便无法完全发挥出 CPU Cache 的优势（想象一下你定义了一个 PaddingObject[] 数组，数组元素在内存中连续，却由于伪共享导致无法使用 CPU Cache 带来的沮丧）。

不知道你注意到没有，实际数据 value + 用于填充的 p1~p6 总共只占据了 7 * 8 = 56 个字节，而 Cache Line 的大小应当是 64 字节，这是有意而为之，在 Java 中，**对象头还占据了 8 个字节(关于对象的内存布局，可以参考《深入理解Java虚拟机》)**，所以一个 PaddingObject 对象可以恰好占据一个 Cache Line。

### Java7 中实现字节填充

在 Java7 之后，一个 JVM 的优化给字节填充造成了一些影响，上面的代码片段 `public long p1, p2, p3, p4, p5, p6;` 会被认为是无效代码被优化掉，有回归到了伪共享的窘境之中。

为了避免 JVM 的自动优化，需要使用继承的方式来填充。

```java
abstract class AbstractPaddingObject{
    protected long p1, p2, p3, p4, p5, p6;// 填充
}

public class PaddingObject extends AbstractPaddingObject{
    public volatile long value = 0L;    // 实际数据
}
```

### Java8 中实现字节填充

```
@Retention(RetentionPolicy.RUNTIME)
@Target({ElementType.FIELD, ElementType.TYPE})
public @interface Contended {
    String value() default "";
}
```

**注意需要同时开启 JVM 参数：-XX:-RestrictContended=false**

### 一些最佳实践

可能有读者会问：作为一个普通开发者，需要关心 CPU Cache 和 Cache Line 这些知识点吗？这就跟前几天比较火的话题：「程序员有必要懂 JVM 吗？」一样，仁者见仁了。但确实有不少优秀的源码在关注着这些问题。他们包括：

**ConcurrentHashMap**

面试中问到要吐的 ConcurrentHashMap 中，使用 @sun.misc.Contended 对静态内部类 CounterCell 进行修饰。另外还包括并发容器 Exchanger 也有相同的操作。

```java
/* ---------------- Counter support -------------- */

/**
 * A padded cell for distributing counts.  Adapted from LongAdder
 * and Striped64.  See their internal docs for explanation.
 */
@sun.misc.Contended static final class CounterCell {
    volatile long value;
    CounterCell(long x) { value = x; }
}
```

**Thread**

Thread 线程类的源码中，使用 @sun.misc.Contended 对成员变量进行修饰。

```java
// The following three initially uninitialized fields are exclusively
// managed by class java.util.concurrent.ThreadLocalRandom. These
// fields are used to build the high-performance PRNGs in the
// concurrent code, and we can not risk accidental false sharing.
// Hence, the fields are isolated with @Contended.

/** The current seed for a ThreadLocalRandom */
@sun.misc.Contended("tlr")
long threadLocalRandomSeed;

/** Probe hash value; nonzero if threadLocalRandomSeed initialized */
@sun.misc.Contended("tlr")
int threadLocalRandomProbe;

/** Secondary seed isolated from public ThreadLocalRandom sequence */
@sun.misc.Contended("tlr")
int threadLocalRandomSecondarySeed;
```

**RingBuffer**

来源于一款优秀的开源框架 Disruptor 中的一个数据结构 **RingBuffer ，**我后续会专门花一篇文章的篇幅来介绍这个数据结构

```java
abstract class RingBufferPad
{
    protected long p1, p2, p3, p4, p5, p6, p7;
}

abstract class RingBufferFields<E> extends RingBufferPad{}
```

使用字节填充和继承的方式来避免伪共享。

# 参考资料

[PolarDB数据库性能大赛Java选手分享](https://github.com/lexburner/kiritoDB)

[JAVA 拾遗 — CPU Cache 与缓存行](https://www.cnkirito.moe/cache-line/)