---
layout:     post
title:      redis数据结构 - 字典
subtitle:   字典
date:       2019-05-09
author:     rosewind
header-img: img/animation/36.png
catalog: true
tags:
    - redis
---

# 前言

字典也是redis中常用的数据结构，类似Java中的HashMap。故主要关注其中的基本数据结构与rehash的过程。

# 定义

## 字典

```c
*
 * 字典
 *
 * 每个字典使用两个哈希表，用于实现渐进式 rehash
 */
typedef struct dict {

    // 特定于类型的处理函数
    dictType *type;

    // 类型处理函数的私有数据
    void *privdata;

    // 哈希表（2 个）
    dictht ht[2];

    // 记录 rehash 进度的标志，值为 -1 表示 rehash 未进行
    int rehashidx;

    // 当前正在运作的安全迭代器数量
    int iterators;

} dict;
```

## 哈希表

```c
/*
 * 哈希表
 */
typedef struct dictht {

    // 哈希表节点指针数组（俗称桶，bucket）
    dictEntry **table;

    // 指针数组的大小
    unsigned long size;

    // 指针数组的长度掩码，用于计算索引值
    unsigned long sizemask;

    // 哈希表现有的节点数量
    unsigned long used;

} dictht;
```

## 哈希表节点

```c
/*
 * 哈希表节点
 */
typedef struct dictEntry {

    // 键
    void *key;

    // 值
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
    } v;

    // 链往后继节点
    struct dictEntry *next;

} dictEntry;
```

## 示例

![](https://redisbook.readthedocs.io/en/latest/_images/graphviz-6989792733a041b23cdc0b8f126434590c50a4e4.svg)



# Rehash

## 过程

字典的 rehash 操作实际上就是执行以下任务：

1. 创建一个比 `ht[0]->table` 更大的 `ht[1]->table` ；
2. 将 `ht[0]->table` 中的所有键值对迁移到 `ht[1]->table` ；
3. 将原有 `ht[0]` 的数据清空，并将 `ht[1]` 替换为新的 `ht[0]` ；

经过以上步骤之后， 程序就在不改变原有键值对数据的基础上， 增大了哈希表的大小。

作为例子， 以下四个小节展示了一次对哈希表进行 rehash 的完整过程。

### 1. 开始 rehash

这个阶段有两个事情要做：

1. 设置字典的 `rehashidx` 为 `0` ，标识着 rehash 的开始；
2. 为 `ht[1]->table` 分配空间，大小至少为 `ht[0]->used` 的两倍；

这时的字典是这个样子：

![](https://redisbook.readthedocs.io/en/latest/_images/graphviz-8af45a72833893e88a305ccd461561b9b00a8816.svg)

### 2. Rehash 进行中

在这个阶段， `ht[0]->table` 的节点会被逐渐迁移到 `ht[1]->table` ， 因为 rehash 是分多次进行的（细节在下一节解释）， 字典的 `rehashidx` 变量会记录 rehash 进行到 `ht[0]` 的哪个索引位置上。

以下是 `rehashidx` 值为 `2` 时，字典的样子：

![](https://redisbook.readthedocs.io/en/latest/_images/graphviz-8c861670330ef855a2e053e280506d6744e1e5d4.svg)

注意除了节点的移动外， 字典的 `rehashidx` 、 `ht[0]->used` 和 `ht[1]->used` 三个属性也产生了变化。

### 3. 节点迁移完毕

到了这个阶段，所有的节点都已经从 `ht[0]` 迁移到 `ht[1]` 了：

![](https://redisbook.readthedocs.io/en/latest/_images/graphviz-15aedc410b921c8a0fd3183c5141b7d1f1ed6eed.svg)

### 4. Rehash 完毕

在 rehash 的最后阶段，程序会执行以下工作：

1. 释放 `ht[0]` 的空间；
2. 用 `ht[1]` 来代替 `ht[0]` ，使原来的 `ht[1]` 成为新的 `ht[0]` ；
3. 创建一个新的空哈希表，并将它设置为 `ht[1]` ；
4. 将字典的 `rehashidx` 属性设置为 `-1` ，标识 rehash 已停止；

以下是字典 rehash 完毕之后的样子：

![](https://redisbook.readthedocs.io/en/latest/_images/graphviz-6d5b0f4115d30fac37af21f3834b5554d8824923.svg)

对比字典 rehash 前后， 新的 `ht[0]` 空间更大， 并且字典原有的键值对也没有被修改或者删除。

## 渐进式Rehash

假设这样一个场景：在一个有很多键值对的字典里， 某个用户在添加新键值对时触发了 rehash 过程， 如果这个 rehash 过程必须将所有键值对迁移完毕之后才将结果返回给用户， 这样的处理方式将是非常不友好的。

另一方面， 要求服务器必须阻塞直到 rehash 完成， 这对于 Redis 服务器本身也是不能接受的。

为了解决这个问题， Redis 使用了渐进式（incremental）的 rehash 方式： 通过将 rehash 分散到多个步骤中进行， 从而避免了集中式的计算。

渐进式 rehash 主要由 `_dictRehashStep` 和 `dictRehashMilliseconds` 两个函数进行：

- `_dictRehashStep` 用于对数据库字典、以及哈希键的字典进行被动 rehash ；
- `dictRehashMilliseconds` 则由 Redis 服务器常规任务程序（server cron job）执行，用于对数据库字典进行主动 rehash ；

### _dictRehashStep

每次执行 `_dictRehashStep` ， `ht[0]->table` 哈希表第一个不为空的索引上的所有节点就会全部迁移到 `ht[1]->table` 。

在 rehash 开始进行之后（`d->rehashidx` 不为 `-1`）， 每次执行一次添加、查找、删除操作， `_dictRehashStep` 都会被执行一次：

![](https://redisbook.readthedocs.io/en/latest/_images/graphviz-121adbc9859ad43720ccb8d4d91bf28062af3256.svg)

因为字典会保持哈希表大小和节点数的比率在一个很小的范围内， 所以每个索引上的节点数量不会很多（从目前版本的 rehash 条件来看，平均只有一个，最多通常也不会超过五个）， 所以在执行操作的同时，对单个索引上的节点进行迁移， 几乎不会对响应时间造成影响。

### dictRehashMilliseconds

`dictRehashMilliseconds` 可以在指定的毫秒数内， 对字典进行 rehash 。

当 Redis 的服务器常规任务执行时， `dictRehashMilliseconds` 会被执行， 在规定的时间内， 尽可能地对数据库字典中那些需要 rehash 的字典进行 rehash ， 从而加速数据库字典的 rehash 进程（progress）。

### 其他措施

在哈希表进行 rehash 时， 字典还会采取一些特别的措施， 确保 rehash 顺利、正确地进行：

- 因为在 rehash 时，字典会同时使用两个哈希表，所以在这期间的所有查找、删除等操作，除了在 `ht[0]` 上进行，还需要在 `ht[1]` 上进行。
- 在执行添加操作时，新的节点会直接添加到 `ht[1]` 而不是 `ht[0]` ，这样保证 `ht[0]` 的节点数量在整个 rehash 过程中都只减不增。

# 参考资料

[Rehash](http://redisbook.com/preview/dict/rehashing.html)

[Redis设计与实现](https://book.douban.com/subject/25900156/)